{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensor Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 1-d zero tensor\n",
    "zeros = torch.zeros(3)\n",
    "print(zeros)\n",
    "\n",
    "# 2-d zero tensor\n",
    "zeros = torch.zeros((2, 3))\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ones tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 1-d '1' tensors\n",
    "ones = torch.ones(3)\n",
    "print(ones)\n",
    "\n",
    "# 2-d '1' tensors\n",
    "ones = torch.ones((2, 3))\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tensor initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# initialization from python list\n",
    "t1 = torch.tensor([1, 2, 3, 4])\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage of PyTorch Tensors\n",
    "\n",
    "Under the hood, PyTorch Tensors are physically stored in consecutive cells for optimized performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "mat_a = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(mat_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.storage()` on the tensor to retrive the underlying sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      " 9\n",
      "[torch.LongStorage of size 9]\n"
     ]
    }
   ],
   "source": [
    "mat_storage = mat_a.storage()\n",
    "print(mat_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the matrix is physically stored in a row-major order. PyTorch uses stride to retrieve the element. `.stride()` can be used to get the stride of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "stride = mat_a.stride()\n",
    "print(stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuple `(3,1)` means, the next row can be found by skipping 3 elements and next column can be found by skipping 1.\n",
    " In other words, the index for mat_a[1, 2] is calculated as `stride[0]*1 + stride[1]*2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transposing** a matrix doesnot change the underlying physical representation of the tensor but creates a view with a different stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "mat_a_t = mat_a.t()\n",
    "print(mat_a_t)\n",
    "stride_t = mat_a_t.stride()\n",
    "print(stride_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer a tensor to GPU\n",
    "\n",
    "We can transfer the tensor to a GPU in one of the following ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_a_gpu = mat_a.cuda()\n",
    "mat_a_gpu = mat_a.to('cuda')\n",
    "mat_a_gpu = mat_a.to('cuda:0') #Indexing the GPU\n",
    "mat_a_gpu = mat_a.cuda(0) # Indexing the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_a_t_gpu = mat_a_t.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 7],\n",
       "        [2, 5, 8],\n",
       "        [3, 6, 9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_a_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serializing a tensor\n",
    "\n",
    "**Using tensor.save()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mat_a, 'mat_a.t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using HDF5** `h5py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Writing\n",
    "\n",
    "f = h5py.File('matrices.hdf5', 'w')\n",
    "dset = f.create_dataset('mat_a', data=mat_a.numpy())\n",
    "f.close()\n",
    "\n",
    "# Reading\n",
    "\n",
    "f = h5py.File('matrices.hdf5', 'r')\n",
    "dset = f['mat_a']\n",
    "last_points = dset[-2:]\n",
    "print(last_points)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More to cover:\n",
    "- dtypes\n",
    "- Named Tensors\n",
    "- NumPy Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a tensor `a` from `list(range(9))`. Predict and then check the size, offset, and stride.\n",
    " - Create a new tensor using `b = a.view(3,3)`. What does `view` do? Check that `a` and `b` share the same storage.\n",
    " - Create a tensorf `c = b[1:, 1:]`. Predict and then check the size, offset, and stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "0\n",
      "(1,)\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      " 0\n",
      " 1\n",
      " 2\n",
      " 3\n",
      " 4\n",
      " 5\n",
      " 6\n",
      " 7\n",
      " 8\n",
      "[torch.LongStorage of size 9]\n",
      "tensor([[4, 5],\n",
      "        [7, 8]])\n",
      "(3, 1)\n",
      "4\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(list(range(9)))\n",
    "print(a.shape)\n",
    "print(a.storage_offset())\n",
    "print(a.stride())\n",
    "\n",
    "b = a.view(3, 3)\n",
    "print(b)\n",
    "print(b.storage())\n",
    "\n",
    "c = b[1:, 1:]\n",
    "print(c)\n",
    "print(c.stride())\n",
    "print(c.storage_offset())\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
